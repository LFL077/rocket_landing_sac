# learning params
buffer_size: 150000 #300000
buffer_size_debug: 100
batch_size: 512
total_steps: 1000000 #2000000
repeats_per_buffer: 1
critic_update_multiplier: 1
actor_update_multiplier: 1
discount_factor: 0.99
learning_rate: 0.0004
exploration_steps: 0
reward_options: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 100, 1, 1, 20, 0, 0, 500
seed: 13

# core SAC params
use_entropy: true
target_entropy: -10.0

# eval settings
eval_num_episodes: 100
eval_steps_ratio: 10000

# wingman required params
debug: false
train: false
display: false
evaluate: false
eval_fitness: false
render_gif: false

weights_directory: 'weights'
version_number: null
mark_number: 0
# log_status: true

increment: false
logging_interval: 10000
max_skips: 5
greater_than: 0.0

wandb: false
wandb_name: ''
wandb_notes: ''
wandb_id: ''
wandb_entity: 'lfl077'
wandb_project: 'rocket_landing_sac'
